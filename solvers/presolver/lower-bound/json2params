#!/usr/bin/python

#  Main authors:
#    Gabriel Hjort Blindell <ghb@kth.se>
#
#  Copyright (c) 2012-2017, Gabriel Hjort Blindell <ghb@kth.se>
#  All rights reserved.
#
#  Redistribution and use in source and binary forms, with or without
#  modification, are permitted provided that the following conditions are met:
#  1. Redistributions of source code must retain the above copyright notice,
#     this list of conditions and the following disclaimer.
#  2. Redistributions in binary form must reproduce the above copyright notice,
#     this list of conditions and the following disclaimer in the documentation
#     and/or other materials provided with the distribution.
#  3. Neither the name of the copyright holder nor the names of its contributors
#     may be used to endorse or promote products derived from this software
#     without specific prior written permission.
#
#  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
#  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
#  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
#  ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER BE LIABLE FOR ANY
#  DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
#  (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
#  LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
#  ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
#  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF
#  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.



#=========
# IMPORTS
#=========

import fractions
import json
import math
import os.path
import sexparser
import sys



#================
# HELP FUNCTIONS
#================

def error(msg):
    sys.stderr.write("ERROR: " + msg + "\n")
    sys.exit(1)

def bumpArrOfSing(json):
    output = []
    for d in json:
        if d is None:
            output.append(d)
        else:
            output.append(d+1)
    return output

def bumpValue(v):
    return v + 1

def bumpArr(json):
    return [ x + 1 for x in json ]

def bumpArrOfArr(json):
    return [ bumpArr(x) for x in json ]

VT_PLAIN = 0
VT_ARRAY1D = 1
VT_ARRAY2D = 2
VT_SET = 3
VT_ARRAY = 4
VC_AS_IS = 0
VC_SET = 1
VC_SINGLETON = 2
def dumpParams(
    json,
    var_name,
    var_type = VT_PLAIN,
    var_range = "",
    var_conv = VC_AS_IS
):
    sys.stdout.write(var_name)
    sys.stdout.write(" = ")
    if var_type == VT_PLAIN:
        sys.stdout.write(convData(json, var_conv))
    elif var_type == VT_ARRAY:
        sys.stdout.write("[")
        lst = ", ".join([ convData(d, var_conv) for d in json ])
        sys.stdout.write(lst)
        sys.stdout.write("]")

    elif var_type == VT_ARRAY1D:
        sys.stdout.write("array1d(")
        sys.stdout.write(var_range)
        sys.stdout.write(", [")
        lst = ", ".join([ convData(d, var_conv) for d in json ])
        sys.stdout.write(lst)
        sys.stdout.write("])")
    elif var_type == VT_ARRAY2D:
        sys.stdout.write("[|")
        rows = []
        for d in json:
            rows.append(", ".join([ convData(e, var_conv) for e in d ]))
        s = ", |".join(rows)
        sys.stdout.write(s)
        sys.stdout.write("|]")
    elif var_type == VT_SET:
        sys.stdout.write("{")
        lst = ", ".join([ convData(d, var_conv) for d in json ])
        sys.stdout.write(lst)
        sys.stdout.write("}")
    else:
        error("unknown variable type")
    sys.stdout.write(";\n\n")

def convData(d, var_conv):
    if var_conv == VC_SET:
        if hasattr(d, "__iter__"):
            return "{" + ", ".join([ str(e) for e in d ]) + "}"
        else:
            return "{" + str(d) + "}"
    elif var_conv == VC_SINGLETON:
        if d is None:
            return "{}"
        else:
            return "{" + str(d) + "}"
    else:
        return str(d)

def parseSExpr(s):
    return sexparser.parse(s)

def removeOperation(json, o):
    def updateOpSet(os):
        return [ p-1 if p < o else p for p in os if p != o ]

    json["fun-num-operations"] = json_data["fun-num-operations"] - 1
    json["fun-copies"] = updateOpSet(json["fun-copies"])
    json["fun-control-ops"] = updateOpSet(json["fun-control-ops"])
    del json["fun-op-placements"][o]

    deps = json["fun-op-dependencies"]
    o_deps = deps[o]
    deps = [ os + o_deps if o in ms else os for os in deps ]
    del deps[o]
    deps = [ updateOpSet(os) for os in deps ]
    json["fun-op-dependencies"] = deps

    json["match-operations-covered"] = \
       [ updateOpSet(os) for os in json["match-operations-covered"] ]
    del json["match-operations-covered"][o]

    return json

def removeMatch(json, m):
    def updateMatchSet(ms):
        return [ n-1 if n < m else n for n in ms if n != m ]

    # Assumes that the first element in each tuple represents the match
    def updateTupleSet(ts):
        new_ts = []
        for t in ts:
            if t[0] == m:
                continue
            if m < t[0]:
                t[0] = t[0] - 1
            new_ts.append(t)
        return new_ts

    json["num-matches"] = json["num-matches"] - 1
    del json["match-operations-covered"][m]
    del json["match-operands-defined"][m]
    del json["match-operands-used"][m]
    del json["match-exterior-operands"][m]
    del json["match-intermediate-operands"][m]
    del json["match-entry-blocks"][m]
    del json["match-spanned-blocks"][m]
    del json["match-consumed-blocks"][m]
    del json["match-code-sizes"][m]
    del json["match-latencies"][m]
    del json["match-constraints"][m]
    del json["match-instruction-ids"][m]

    json["match-copy-instrs"] = updateMatchSet(json["match-copy-instrs"])
    json["match-kill-instrs"] = updateMatchSet(json["match-kill-instrs"])
    json["match-null-instrs"] = updateMatchSet(json["match-null-instrs"])
    json["match-phi-instrs"] = updateMatchSet(json["match-phi-instrs"])
    new_ill_combs = [ updateMatchSet(ms) for ms in json["illegal-match-combs"] ]
    json["illegal-match-combs"] = [ ms for ms in new_ill_combs if len(ms) > 1 ]

    json["match-valid-value-locs"] = \
        updateTupleSet(json["match-valid-value-locs"])
    json["match-same-value-locs"] = \
        updateTupleSet(json["match-same-value-locs"])
    json["match-input-def-edges"] = \
        updateTupleSet(json["match-input-def-edges"])
    json["match-output-def-edges"] = \
        updateTupleSet(json["match-output-def-edges"])
    json["match-fall-through-block"] = \
        updateTupleSet(json["match-fall-through-block"])

    return json

def computeOpCoverageDict(json):
    D = {}
    for m in range(json["num-matches"]):
        key = getOpCoverageKey(json["match-operations-covered"][m])
        m_cost = json["match-latencies"][m]
        if key in D:
            best_m = D[key]
            best_cost = json["match-latencies"][best_m]
        else:
            best_cost = sys.maxint
        if m_cost < best_cost:
            D[key] = m
    return D

def getOpCoverageKey(os):
    key = ""
    os_str = map(str, os)
    return ",".join(os_str)


#=============
# MAIN SCRIPT
#=============

# Check arguments
if len(sys.argv) < 2:
    sys.stderr.write("No JSON file provided\n")
    sys.exit(1)
if len(sys.argv) > 2:
    error("Too many arguments\n")
json_file = sys.argv[1]
if not os.path.isfile(json_file):
    error("JSON file '" + json_file +"' not found")

# Read JSON file
json_data = []
with open(json_file, 'r') as file:
    json_data = json.load(file)

# Compute GCD of frequencies
fqs = json_data["fun-block-exec-freqs"]
scaled = []
g = fqs[0]
for x in fqs:
    g = fractions.gcd(g, x)
for x in fqs:
    scaled.append(x / g)

# Remove all copy operations that is coverable by a zero-cost pattern
copy_ops = set()
for m in json_data["match-copy-instrs"]:
    if json_data["match-latencies"][m] == 0:
        copy_ops = copy_ops | set(json_data["match-operations-covered"][m])
for m in range(json_data["num-matches"]):
    new_ops_covered = []
    for p in json_data["match-operations-covered"][m]:
        if p not in copy_ops:
            new_ops_covered.append(p - len([ q for q in copy_ops if q < p ]))
    json_data["match-operations-covered"][m] = new_ops_covered
op_places = json_data["fun-op-placements"]
offset = 0
for o in copy_ops:
    i = o - offset
    del op_places[i]
    offset = offset + 1
json_data["fun-op-placements"] = op_places
json_data["fun-num-operations"] = \
    json_data["fun-num-operations"] - len(copy_ops)

# Compute cover cost for operations
min_exec_freq_per_op  = []
for o in range(json_data["fun-num-operations"]):
    bs = json_data["fun-op-placements"][o]
    min_freq = sys.maxint
    for b in bs:
        min_freq = min(min_freq, json_data["fun-block-exec-freqs"][b])
    min_exec_freq_per_op.append(min_freq / g)

# Produce 'match-fall-through-block' parameters
params = []
for m in range(json_data["num-matches"]):
    for c in json_data["match-constraints"][m]:
        l = parseSExpr(c)
        if ( len(l) == 2 and l[0] == "fall-through"
             and len(l[1]) == 2 and l[1][0] == "block-of-bnode"
             and len(l[1][1]) == 2 and l[1][1][0] == "ai"
           ):
            fall_b = int(l[1][1][1])
            params.append([m, fall_b])
json_data["match-fall-through-block"] = params

# Remove matches that are useless for this model
queue = range(json_data["num-matches"])
while len(queue) > 0:
    m = queue.pop(0)
    if len(json_data["match-operations-covered"][m]) == 0:
        json_data = removeMatch(json_data, m)
        queue = [n-1 for n in queue]

# Sort operation coverage information
for i in range(len(json_data["match-operations-covered"])):
    os = json_data["match-operations-covered"][i]
    json_data["match-operations-covered"][i] = sorted(os)

# Remove matches that span no blocks and cover the same operations at equal or
# greater cost
D = computeOpCoverageDict(json_data)
dominated_ms = []
spanning_ms = \
    set([ m for m in range(json_data["num-matches"])
          if len(json_data["match-spanned-blocks"][m]) > 0
        ])
for m in range(json_data["num-matches"]):
    if m in spanning_ms:
        continue
    key = getOpCoverageKey(json_data["match-operations-covered"][m])
    if D[key] != m:
        dominated_ms.append(m)
queue = dominated_ms
while len(queue) > 0:
    m = queue.pop(0)
    json_data = removeMatch(json_data, m)
    queue = [n-1 for n in queue]

# Dump parameters for 1-based solver
dumpParams( json_data["fun-num-operations"]
          , "numOperationsInFunction"
          )
dumpParams( json_data["fun-num-blocks"]
          , "numBlocksInFunction"
          )
dumpParams( json_data["num-matches"]
          , "numMatches"
          )
dumpParams( g
          , "execFrequencyGCD"
          )
dumpParams( min_exec_freq_per_op
          , "minExecFreqPerOpInFunction"
          , VT_ARRAY1D
          , "allOperationsInFunction"
          )
dumpParams( bumpArrOfArr(json_data["match-operations-covered"])
          , "operationsCoveredByMatch"
          , VT_ARRAY1D
          , "allMatches"
          , VC_SET
          )
dumpParams( bumpArrOfSing(json_data["match-entry-blocks"])
          , "entryBlockOfMatch"
          , VT_ARRAY1D
          , "allMatches"
          , VC_SINGLETON
          )
dumpParams( bumpArrOfArr(json_data["match-fall-through-block"])
          , "fallThroughBlockOfMatch"
          , VT_ARRAY2D
          )
dumpParams( json_data["match-latencies"]
          , "latencyOfMatch"
          , VT_ARRAY1D
          , "allMatches"
          )
