#!/usr/bin/python

#  Main authors:
#    Gabriel Hjort Blindell <ghb@kth.se>
#    Mats Carlsson <mats.carlsson@ri.se>
#
#  Copyright (c) 2012-2017, Gabriel Hjort Blindell <ghb@kth.se>
#  All rights reserved.
#
#  Redistribution and use in source and binary forms, with or without
#  modification, are permitted provided that the following conditions are met:
#  1. Redistributions of source code must retain the above copyright notice,
#     this list of conditions and the following disclaimer.
#  2. Redistributions in binary form must reproduce the above copyright notice,
#     this list of conditions and the following disclaimer in the documentation
#     and/or other materials provided with the distribution.
#  3. Neither the name of the copyright holder nor the names of its contributors
#     may be used to endorse or promote products derived from this software
#     without specific prior written permission.
#
#  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
#  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
#  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
#  ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER BE LIABLE FOR ANY
#  DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
#  (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
#  LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
#  ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
#  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF
#  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.



#=========
# IMPORTS
#=========

import json
import os.path
import sys



#================
# HELP FUNCTIONS
#================

def error(msg):
    sys.stderr.write("ERROR: " + msg + "\n")
    sys.exit(1)

# A match m1 dominates another match m2 if:
#    - neither is a null instruction,
#    - neither match occurs in the parameters "same-loc", "in-block", and
#      "in-block-succ" (TODO: relax?),
#    - the tuple <latency of m1, index of m1> is lexicographically smaller than
#      the tuple <latency of m2, index of m2>,
#    - both matches cover exactly the same operations,
#    - both matches define exactly the same data,
#    - both matches use exactly the same data,
#    - both matches have the same entry block,
#    - both matches span across the same blocks,
#    - both matches apply the def-dom-use constraint,
#    - if m1 defines any constraints in the parameters "match-valid-value-locs"
#      or "match-valid-value-loc-ranges", then m2 defines constraints that are
#      at least as strong,
#      and
#    - both matches have exactly the same auxiliary constraints (TODO: relax?).
def matchesDominatedBy(json, m1, dominable_matches):
    def computeDominableMatchsetCandidates():
        def findMatchesCovering(ops_to_cover, m_cands, selected_ms):
            if len(ops_to_cover) == 0:
                return selected_ms

            all_solutions = []
            for i in range(len(m_cands)):
                m = m_cands[i]
                m_op_cover_set = set(json["match-operations-covered"][m])
                if m_op_cover_set <= ops_to_cover:
                    remaining_ops = ops_to_cover - m_op_cover_set
                    remaining_ms = [n for n in m_cands if n != m]
                    if len(selected_ms) > 0:
                        new_selected_ms = [ ms + [m] for ms in selected_ms ]
                    else:
                        new_selected_ms = [[m]]
                    solutions = findMatchesCovering(remaining_ops,
                                                    remaining_ms,
                                                    new_selected_ms)
                    all_solutions = ( all_solutions +
                                      [ set(ms) for ms in solutions
                                        if set(ms) not in all_solutions
                                      ]
                                    )
            return [ list(ms) for ms in all_solutions ]

        # Gather combinations of matches that collectively cover the same
        # operations as m1
        m1_op_cover_set = set(json["match-operations-covered"][m1])
        ms_covering_same_ops = [ m for m in dominable_matches
                                 if m != m1 and
                                    set(json["match-operations-covered"][m]) <=
                                    m1_op_cover_set
                               ]
        return findMatchesCovering(m1_op_cover_set, ms_covering_same_ops, [])

    def hasPotentialOverlapWithOtherMatches(ms_set):
        all_dom_ms = set([ m for ms in ms_set for m in ms ])
        m1_ops = json["match-operations-covered"][m1]
        for o in m1_ops:
            other_ms = [ m for m in range(json_data["num-matches"])
                         if ( o in json["match-operations-covered"][m] and
                              m != m1 and
                              m not in all_dom_ms
                            )
                       ]
            if len(other_ms) > 0:
                # Potential overlap; m1 can only dominate single-match
                # candidates
                return True

        # All checks passed
        return False

    def useOfInternalValuesByOtherMatches(ms_set):
        all_dom_ms = set([ m for ms in ms_set for m in ms ])
        m1_int_values = set([ d for p in json["match-internal-operands"][m1]
                                for d in json["operand-alternatives"][p]
                            ])
        other_ms = [ m for m in range(json_data["num-matches"])
                     if m != m1 and m not in all_dom_ms
                   ]
        for m2 in other_ms:
            for p in json["match-operands-used"][m2]:
                d = json["operand-alternatives"][p]
                if set(d) <= m1_int_values:
                    # Use of m1's internal values; m1 can only dominate
                    # single-match candidates
                    return True

        # All checks passed
        return False

    def hasLessOrEqualCost(ms):
        # Compute maximum cost of selecting m1
        m1_ops = json["match-operations-covered"][m1]
        m1_places = set(range(0, json["fun-num-blocks"]))
        for o in m1_ops:
            m1_places = m1_places & set(json["fun-op-placements"][o])
        if len(m1_places) == 0:
            # m1 can never be selected
            return False
        m1_latency = json["match-latencies"][m1]
        m1_max_cost = 0
        for b in m1_places:
            c = m1_latency * json["fun-block-exec-freqs"][b]
            m1_max_cost = max(m1_max_cost, c)

        # Compute minimum cost of selecting ms
        ms_min_cost = 0
        for m2 in ms:
            m2_ops = json["match-operations-covered"][m2]
            m2_places = set(range(0, json["fun-num-blocks"]))
            for o in m2_ops:
                m2_places = m2_places & set(json["fun-op-placements"][o])
            if len(m2_places) == 0:
                # m2 can never be selected
                return False
            m2_latency = json["match-latencies"][m2]
            m2_min_cost = 0
            for b in m2_places:
                c = m2_latency * json["fun-block-exec-freqs"][b]
                m2_min_cost = max(m2_min_cost, c)
            ms_min_cost = ms_min_cost + m2_min_cost

        return ( m1_max_cost < ms_min_cost or
                 ( m1_max_cost == ms_min_cost and
                   ( len(ms) > 1 or m1 < ms[0] )
                 )
               )

    def hasSameEntry(ms):
        m1_entry = json["match-entry-blocks"][m1]
        if m1_entry is not None:
            m1_entry = set([m1_entry])
        else:
            m1_entry = set()
        ms_entries = set()
        for m in ms:
            m_entry = json["match-entry-blocks"][m]
            if m_entry is not None:
                ms_entries.add(m_entry)
        return m1_entry == ms_entries

    def spansSameBlocks(ms):
        m1_spanned = set(json["match-spanned-blocks"][m1])
        ms_spanned = set()
        for m in ms:
            ms_spanned.update(set(json["match-spanned-blocks"][m]))
        return m1_spanned == ms_spanned

    def hasNoConflictingDefEdges(ms):
        # Check edges imposed by function graph
        m1_data = ( set([ d for p in json["match-operands-defined"][m1]
                            for d in json["operand-alternatives"][p]
                        ]) |
                    set([ d for p in json["match-operands-used"][m1]
                            for d in json["operand-alternatives"][p]
                        ])
                  )
        f_def_blocks = set()
        for t in json["fun-def-edges"]:
            if t[1] in m1_data:
                f_def_blocks.add(t[0])

        # Check edges imposed by candidate set
        ms_def_blocks = set()
        for t in json["match-input-def-edges"]:
            if t[0] in ms:
                ms_def_blocks.add(t[1])
        for t in json["match-output-def-edges"]:
            if t[0] in ms:
                ms_def_blocks.add(t[1])
        return (len(f_def_blocks) < 2 and len(ms_def_blocks) < 2)

    def areLocDomainsAtLeastAsStrong(ms):
        O = json["operand-alternatives"]

        # Gather m1 operands to check
        m1_def_ops = set(json["match-operands-defined"][m1])
        m1_use_ops = set(json["match-operands-used"][m1])
        m1_ops = ( (m1_def_ops | m1_use_ops) -
                   set(json["match-internal-operands"][m1])
                 )

        # Check match-valid-value-locs constraints
        locs = json["match-valid-value-locs"]
        m1_locs = [t for t in locs if t[0] == m1]
        for m1_t in m1_locs:
            # Find constraint in ms that is at least as strong
            found = False
            for m2_t in [t for t in locs if t[0] in ms]:
                if set(O[m1_t[1]]) <= set(O[m2_t[1]]):
                    m1_r = m1_t[2]
                    m2_r = m2_t[2]
                    if m1_r == m2_r:
                        # Matching constraint
                        found = True
                    else:
                        # Conflicting constraint
                        return False

            # No such constraint found
            if not found:
                return False

        # Check match-valid-value-loc-ranges constraints
        loc_ranges = json["match-valid-value-loc-ranges"]
        m1_loc_ranges = [t for t in loc_ranges if t[0] == m1]
        for m1_t in m1_loc_ranges:
            # Find constraint in m2 that is at least as strong
            found = False
            for m2_t in [t for t in loc_ranges if t[0] in ms]:
                if set(O[m1_t[1]]) <= set(O[m2_t[1]]):
                    m1_rs = set(range(m1_t[2], m1_t[3]+1))
                    m2_rs = set(range(m2_t[2], m2_t[3]+1))
                    if m2_rs <= m1_rs:
                        # Matching constraint
                        found = True
                    else:
                        # Conflicting constraint
                        return False

            # No such constraint found
            if not found:
                return False

        # All checks have passed
        return True

    def hasSameConstraints(ms):
        m1_cons = set(json["match-constraints"][m1])
        ms_cons = set()
        for m in ms:
            ms_cons.update(json["match-constraints"][m])
        return m1_cons == ms_cons



    dominable_matchset_candidates = computeDominableMatchsetCandidates()

    potential_overlap = \
        hasPotentialOverlapWithOtherMatches(dominable_matchset_candidates)
    use_of_int_values = \
        useOfInternalValuesByOtherMatches(dominable_matchset_candidates)

    # Check for dominance
    dominated_ms = []
    not_dominated_ms = []
    for ms in [ms for ms in dominable_matchset_candidates]:
        if ( ( not potential_overlap or
               len(ms) == 1
             ) and
             ( not use_of_int_values or
               len(ms) == 1
             ) and
             hasLessOrEqualCost(ms) and
             hasSameEntry(ms) and
             spansSameBlocks(ms) and
             hasNoConflictingDefEdges(ms) and
             areLocDomainsAtLeastAsStrong(ms) and
             hasSameConstraints(ms)
           ):
            dominated_ms.append(ms)
        else:
            not_dominated_ms.append(ms)

    # Gather matches which appear in a dominated set and not in any
    # non-dominated set
    illegal_dom_matches = set()
    for ms in not_dominated_ms:
        illegal_dom_matches.update(ms)
    dom_matches = set()
    for ms in dominated_ms:
        ms_okay = True
        for m in ms:
            if m in illegal_dom_matches:
                ms_okay = False
                break

        if ms_okay:
            for m in ms:
                dom_matches.add(m)

    return list(dom_matches)



#=============
# MAIN SCRIPT
#=============

# Check arguments
if len(sys.argv) < 2:
    sys.stderr.write("No JSON file given\n")
    sys.exit(1)
if len(sys.argv) > 2:
    sys.stderr.write("Too many arguments\n")
    sys.exit(1)
json_file = sys.argv[1]
if not os.path.isfile(json_file):
    error("JSON file '" + json_file +"' not found")

# Read JSON file
json_data = {}
with open(json_file, 'r') as file:
    json_data = json.load(file)

# Gather matches eligable for domination
illegal_dominators = \
    ( set(json_data["match-null-instrs"]) |
      set([ int(t[0]) for t in json_data["match-same-value-locs"] ]) |
      set([ int(t[0]) for t in json_data["match-fall-through-block"] ]) |
      set([ m for m in range(json_data["num-matches"])
            if len(json_data["match-operations-covered"][m]) == 0
          ])
    )
dominator_candidates = [ m for m in range(json_data["num-matches"])
                         if m not in illegal_dominators
                       ]
illegal_dominatees = \
    ( set(json_data["match-kill-instrs"]) |
      set([ m for m in range(json_data["num-matches"])
            if len(json_data["match-operations-covered"][m]) == 0
          ])
    )
dominable_matches = [ m for m in range(json_data["num-matches"])
                      if m not in illegal_dominatees
                    ]

# Computed dominated matches
dominated_match_sublists = [ matchesDominatedBy(json_data, m, dominable_matches)
                             for m in dominator_candidates
                           ]
dominated_match_set = set([ m for ms in dominated_match_sublists for m in ms])

d_json_data = {}
d_json_data["dominated-matches-ai"] = list(dominated_match_set)

# Print JSON
print json.dumps(d_json_data)
